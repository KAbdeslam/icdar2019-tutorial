{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchmore import layers, flex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# LAYOUT MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Layout Analysis\n",
    "\n",
    "Goals of document layout analysis:\n",
    "\n",
    "- identify text/image regions on pages\n",
    "- find text lines\n",
    "- find words within text lines\n",
    "- determine reading order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "FIXME references and sample images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# RCNN for Layout Analysis\n",
    "\n",
    "- RCNN has been used for word bounding boxes in scene text\n",
    "- likely does not work well for whole page segmentation\n",
    "  - regions often not exactly axis-aligned rectangles\n",
    "  - regions wildly differ in scale and shape\n",
    "  - region hypotheses likely difficult to regress from moving windows\n",
    "\n",
    "FIXME reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Layout Analysis as Semantic Segmentation\n",
    "\n",
    "- semantic image segmentation = image-to-image transformation\n",
    "- each image is classified into one of several different semantic classes\n",
    "- possible pixel classes for layout analysis:\n",
    "  - text / image / table / figure / background\n",
    "  - baseline / background\n",
    "  - centerline / background\n",
    "  - text / image / text line separator / column separator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# What do we label?\n",
    "\n",
    "Possibilities:\n",
    "\n",
    "- foreground pixels only\n",
    "- all pixels in a rectangle / region\n",
    "- leave it up to the algorithm\n",
    "\n",
    "Very different results:\n",
    "\n",
    "- foreground/algorithm = we don't know which pixels belong together\n",
    "- all pixels in a region = group pixels together by connected components\n",
    "- labeling / segmentation closely linked to intended post-processing for region extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Page Level Segmentation\n",
    "\n",
    "Page level segmentation divides images into text regions, image regions, and background.\n",
    "\n",
    "- precise pixel-level segmentations are not usually needed\n",
    "- segmentations can be computed at a lower level of resolution\n",
    "- simple properties like text/image/background can be computed based on local texture / statistics\n",
    "- separating adjacent text columns or images may be difficult, since background gaps may be narrow\n",
    "\n",
    "Different uses:\n",
    "\n",
    "- simply mask out non-text regions for further processing (basic binary map sufficient)\n",
    "- extract text regions via connected components (requires higher quality segmentation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Simple Approach\n",
    "\n",
    "Word segmentation:\n",
    "\n",
    "- assume training data consists of page images and word bounding boxes\n",
    "- create a binary target that is 1 inside word bounding boxes and 0 elsewhere\n",
    "- learn an image-to-image model predicting the binary map from the input document image\n",
    "\n",
    "Problem:\n",
    "\n",
    "- word bounding boxes are often overlapping\n",
    "- how do we turn the resulting binary image into something we can feed to a word recognizer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Centerline / Baseline Approach\n",
    "\n",
    "Word/line segmentation:\n",
    "\n",
    "- assume training data consists of page images and word/line bounding boxes\n",
    "- create a binary image that marks either the center line or the baseline of each bounding box\n",
    "- learn an image-to-image model predicting the centerline/baseline map from the input document image:\n",
    "\n",
    "Properties:\n",
    "\n",
    "- works better than the simple approach\n",
    "- still need to use non-DL mechanisms to find the word/line bounding boxes from the seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Marker Plus Separator Approach\n",
    "\n",
    "Word/line segmentation:\n",
    "\n",
    "- assume training data consists of page images and word/line bounding boxes\n",
    "- three output classes:\n",
    "  - background\n",
    "  - marker (center of bounding box)\n",
    "  - boundary (outline of bounding box)\n",
    "- train image-to-image segmentation model to output all three classes\n",
    "- recover word/line images via marker morphology\n",
    "\n",
    "Properties:\n",
    "\n",
    "- functions like RCNN, in that it finds both the location and the size of object instances (words/lines)\n",
    "- simpler to understand/tune: we can see the marker/boundary proposals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "FIXME examples from marker-plus-separator approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Footprint and Global Context for Page Segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Semi-Supervised and Weakly Supervised Approaches\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
